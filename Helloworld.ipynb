{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv (from -r requirements.txt (line 1))\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from -r requirements.txt (line 2)) (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 2)) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from openai->-r requirements.txt (line 2)) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai->-r requirements.txt (line 2)) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai->-r requirements.txt (line 2)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai->-r requirements.txt (line 2)) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests>=2.20->openai->-r requirements.txt (line 2)) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->openai->-r requirements.txt (line 2)) (0.4.6)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\hp\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv (from -r requirements.txt (line 1))Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting openai (from -r requirements.txt (line 2))\n",
      "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting anyio<4,>=3.5.0 (from openai->-r requirements.txt (line 2))\n",
      "  Using cached anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai->-r requirements.txt (line 2))\n",
      "  Using cached distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai->-r requirements.txt (line 2))\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai->-r requirements.txt (line 2))\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "     ---------------------------------------- 0.0/65.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/65.2 kB ? eta -:--:--\n",
      "     ------ --------------------------------- 10.2/65.2 kB ? eta -:--:--\n",
      "     ----------------- -------------------- 30.7/65.2 kB 330.3 kB/s eta 0:00:01\n",
      "     ----------------------- -------------- 41.0/65.2 kB 245.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 65.2/65.2 kB 319.6 kB/s eta 0:00:00\n",
      "Collecting sniffio (from openai->-r requirements.txt (line 2))\n",
      "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
      "Collecting tqdm>4 (from openai->-r requirements.txt (line 2))\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions<5,>=4.5 (from openai->-r requirements.txt (line 2))\n",
      "  Using cached typing_extensions-4.8.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting idna>=2.8 (from anyio<4,>=3.5.0->openai->-r requirements.txt (line 2))\n",
      "  Downloading idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2))\n",
      "  Downloading certifi-2023.11.17-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 2))\n",
      "  Using cached httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 2))\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2))\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 2))\n",
      "  Downloading pydantic_core-2.14.5-cp311-none-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting colorama (from tqdm>4->openai->-r requirements.txt (line 2))\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "   ---------------------------------------- 0.0/221.4 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/221.4 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 41.0/221.4 kB ? eta -:--:--\n",
      "   ---------- ---------------------------- 61.4/221.4 kB 409.6 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 71.7/221.4 kB 357.2 kB/s eta 0:00:01\n",
      "   ------------ -------------------------- 71.7/221.4 kB 357.2 kB/s eta 0:00:01\n",
      "   ---------------- ---------------------- 92.2/221.4 kB 308.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 143.4/221.4 kB 425.3 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 143.4/221.4 kB 425.3 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 153.6/221.4 kB 353.1 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 194.6/221.4 kB 406.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- 221.4/221.4 kB 422.4 kB/s eta 0:00:00\n",
      "Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "   ---------------------------------------- 0.0/75.0 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 41.0/75.0 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 75.0/75.0 kB 1.0 MB/s eta 0:00:00\n",
      "Using cached httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "   ---------------------------------------- 0.0/381.9 kB ? eta -:--:--\n",
      "   ---- ----------------------------------- 41.0/381.9 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 122.9/381.9 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 153.6/381.9 kB 1.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 204.8/381.9 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 256.0/381.9 kB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 307.2/381.9 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  378.9/381.9 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 381.9/381.9 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.14.5-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/1.9 MB 4.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/1.9 MB 1.5 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.3/1.9 MB 947.5 kB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.3/1.9 MB 999.9 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.4/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.5/1.9 MB 936.0 kB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.6/1.9 MB 974.4 kB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.7/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.7/1.9 MB 1.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 0.8/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 0.8/1.9 MB 1.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 0.9/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.0/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.1/1.9 MB 926.1 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.1/1.9 MB 933.2 kB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.2/1.9 MB 922.8 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 919.3 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 919.3 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 919.3 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 919.3 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 914.8 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 926.0 kB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 926.0 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.4/1.9 MB 875.9 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 869.7 kB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 869.7 kB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.5/1.9 MB 850.9 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.6/1.9 MB 896.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.9 MB 916.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.7/1.9 MB 895.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.8/1.9 MB 915.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 937.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 931.3 kB/s eta 0:00:00\n",
      "Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
      "   ---------------------------------------- 0.0/61.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 61.6/61.6 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "   ---------------------------------------- 0.0/162.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 10.2/162.5 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 143.4/162.5 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 162.5/162.5 kB 1.6 MB/s eta 0:00:00\n",
      "Installing collected packages: typing-extensions, sniffio, python-dotenv, idna, h11, distro, colorama, certifi, annotated-types, tqdm, pydantic-core, httpcore, anyio, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.8.0\n",
      "    Uninstalling typing_extensions-4.8.0:\n",
      "      Successfully uninstalled typing_extensions-4.8.0\n",
      "  Attempting uninstall: sniffio\n",
      "    Found existing installation: sniffio 1.3.0\n",
      "    Uninstalling sniffio-1.3.0:\n",
      "      Successfully uninstalled sniffio-1.3.0\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.0.0\n",
      "    Uninstalling python-dotenv-1.0.0:\n",
      "      Successfully uninstalled python-dotenv-1.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2023.5.7\n",
      "    Uninstalling certifi-2023.5.7:\n",
      "      Successfully uninstalled certifi-2023.5.7\n",
      "  Attempting uninstall: annotated-types\n",
      "    Found existing installation: annotated-types 0.6.0\n",
      "    Uninstalling annotated-types-0.6.0:\n",
      "      Successfully uninstalled annotated-types-0.6.0\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.65.0\n",
      "    Uninstalling tqdm-4.65.0:\n",
      "      Successfully uninstalled tqdm-4.65.0\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.3\n",
      "    Uninstalling pydantic_core-2.14.3:\n",
      "      Successfully uninstalled pydantic_core-2.14.3\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.5.1\n",
      "    Uninstalling pydantic-2.5.1:\n",
      "      Successfully uninstalled pydantic-2.5.1\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.27.8\n",
      "    Uninstalling openai-0.27.8:\n",
      "      Successfully uninstalled openai-0.27.8\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 certifi-2023.11.17 colorama-0.4.6 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 idna-3.6 openai-1.3.7 pydantic-2.5.2 pydantic-core-2.14.5 python-dotenv-1.0.0 sniffio-1.3.0 tqdm-4.66.1 typing-extensions-4.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3 -> 23.3.1\n",
      "[notice] To update, run: C:\\Users\\hp\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --upgrade --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\hp\\\\OneDrive\\\\Desktop\\\\learning\\\\OPEN AI\\\\.env'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "find_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv , find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8aHMBcBKn64atmERQribP1VGJErVg',\n",
       " 'choices': [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='8 + 7 is equal to 15.', role='assistant', function_call=None, tool_calls=None), logprobs=None)],\n",
       " 'created': 1703657219,\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_772e8125bb',\n",
       " 'usage': CompletionUsage(completion_tokens=10, prompt_tokens=14, total_tokens=24)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'8 + 7 is equal to 15.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str) -> str :\n",
    "    responce : ChatCompletion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                'role' : 'user',\n",
    "                'content' : prompt,\n",
    "\n",
    "        }\n",
    "        ],\n",
    "        model = 'gpt-3.5-turbo-1106'\n",
    "    )\n",
    "    display(dict(responce))\n",
    "    return responce.choices[0].message.content\n",
    "\n",
    "chat_completion('what is 8 + 7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the openai key is correct or incorrect\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RCC stands for Reinforced Concrete Cement. Reinforced concrete is a composite material made of concrete and reinforcement bars or mesh. It is widely used in construction for its excellent strength, durability, and versatility. RCC is commonly used in the construction of buildings, bridges, dams, and other structures.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "# multirole\n",
    "def chat_completion(prompt : str) -> str :\n",
    "    responce : ChatCompletion = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "        messages = [\n",
    "            \n",
    "                {'role' : 'system' , 'content' : 'Now you are a civil engineer proessor and have ability to describe knoeladge about civil engineering '},\n",
    "                {'role' : 'user' , 'content' : prompt },\n",
    "            \n",
    "        ],)\n",
    "            \n",
    "    \n",
    "    return responce.choices[0].message.content\n",
    "chat_completion(' RCC stands for ? ')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8ST1s8ixUa30Hf3hGBr6MiMUMKOyS',\n",
       " 'choices': [Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='PCC stands for Plain Cement Concrete. It is a construction material made from a mixture of cement, water, fine aggregate, and coarse aggregate. PCC is commonly used in the construction of foundations, pavements, and drainage structures.', role='assistant', function_call=None, tool_calls=None))],\n",
       " 'created': 1701795464,\n",
       " 'model': 'gpt-3.5-turbo-1106',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': 'fp_eeff13170a',\n",
       " 'usage': CompletionUsage(completion_tokens=47, prompt_tokens=24, total_tokens=71)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'PCC stands for Plain Cement Concrete. It is a construction material made from a mixture of cement, water, fine aggregate, and coarse aggregate. PCC is commonly used in the construction of foundations, pavements, and drainage structures.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str) -> str :\n",
    "    responce : ChatCompletion = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "        messages = [\n",
    "            {'role' : 'system', 'content' : 'Now you are a civil engineer'},\n",
    "            {'role' : 'user' ,'content' : prompt }\n",
    "        ]\n",
    "    )\n",
    "    display(dict(responce))\n",
    "    return responce.choices[0].message.content\n",
    "chat_completion('what is PCC stands for?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 * 4 equals 12.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str) -> str :\n",
    "    responce : ChatCompletion = client.chat.completions.create(\n",
    "       model = 'gpt-3.5-turbo-1106',\n",
    "        messages = [\n",
    "            {'role' : 'user', 'content' : prompt }\n",
    "        ],\n",
    "        \n",
    "    )\n",
    "\n",
    "    return responce.choices[0].message.content\n",
    "\n",
    "chat_completion(' what is 3 * 4 ')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This\n",
      " is\n",
      " an\n",
      " example\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client : OpenAI = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = [{'role' : 'user' , 'content' : ' say This is a example' }],\n",
    "    stream = True,\n",
    ")\n",
    "\n",
    "for part in stream :\n",
    "    print(part.choices[0].delta.content or \"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This\n",
      " is\n",
      " a\n",
      " test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = [{'role' : 'user' , 'content' : 'say This is a test'}],\n",
    "    stream = True,\n",
    ")\n",
    "\n",
    "for part in stream :\n",
    "    print(part.choices[0].delta.content or \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'44 divided by 4 is equal to 11.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str) -> str :\n",
    "    responce : ChatCompletion = client.chat.completions.create(\n",
    "        messages = [\n",
    "            {\n",
    "                'role' : 'user',\n",
    "                'content' : prompt\n",
    "            }\n",
    "        ],\n",
    "        model = 'gpt-3.5-turbo-1106'\n",
    "    )\n",
    "\n",
    "    return responce.choices[0].message.content\n",
    "chat_completion('what is 44 / 4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The history of electricity dates back to ancient civilizations, where early discoveries of static electricity were made. The modern understanding and harnessing of electricity began in the 18th century with the pioneering work of scientists such as Benjamin Franklin and Alessandro Volta.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multi roles\n",
    "\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "def chat_completion(prompt : str) -> str :\n",
    "    responce : ChatCompletion = client.chat.completions.create(\n",
    "        model = 'gpt-3.5-turbo-1106',\n",
    "       messages =  [\n",
    "                {'role' : 'system','content' : 'Now you are a electrical engineering professor'},\n",
    "                {'role' : 'user', 'content' : prompt}\n",
    "        ],\n",
    "\n",
    "    )\n",
    "\n",
    "    return responce.choices[0].message.content\n",
    "chat_completion('tell me history of electricity in 2 lines??')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This\n",
      " is\n",
      " an\n",
      " example\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# streaming\n",
    "\n",
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    messages = [{'role' : 'user', 'content' : 'say This is an example.'}],\n",
    "    stream = True\n",
    ")\n",
    "\n",
    "for parts in stream :\n",
    "    print(parts.choices[0].delta.content or \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv())\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"monthsWith30Days\": [\n",
      "    \"April\",\n",
      "    \"June\",\n",
      "    \"September\",\n",
      "    \"November\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# json format\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo-1106',\n",
    "    response_format = {'type' : 'json_object'},\n",
    "    messages = [\n",
    "        {'role' : 'system', 'content' : 'you are a helpful assistant and give output  in json object'},\n",
    "        {'role' : 'user', 'content' : 'please tell me months name which have 30 days'},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "April\n"
     ]
    }
   ],
   "source": [
    "# parse json\n",
    "# convert JSON into Python\n",
    "\n",
    "import json \n",
    "\n",
    "obj : dict[str, list[str]] = json.loads(response.choices[0].message.content)\n",
    "\n",
    "print(obj['monthsWith30Days'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calling\n",
    "\n",
    "def get_current_weather(location : str , unit : str = 'farenheit') -> str :\n",
    "    '''Get the current weather in a given location'''\n",
    "    if 'tokyo' in location.lower():\n",
    "        return json.dumps({'location' : 'Tokyo', 'temprature' : '10', 'unit' : 'celsius'}),\n",
    "    elif 'san francisco' in location.lower():\n",
    "        return json.dumps({'location' : 'San francisco', 'temprature' : '72', 'unit' : 'farenheit'}),\n",
    "    elif 'paris' in location.lower():\n",
    "        return json.dumps({'location' : 'Paris', 'temprature' : '10', 'unit' : 'celsius'})\n",
    "    else :\n",
    "        return json.dumps({'location' : location , 'temprature' : 'unknown'})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletionMessage, ChatCompletion\n",
    "\n",
    "def run_conversation(main_request : str) -> str :\n",
    "    messages = [{'role': 'user' , 'content' : main_request }]\n",
    "\n",
    "    tools = [\n",
    "        {\n",
    "        'type' : 'function',\n",
    "        'function' : {\n",
    "            'name' : 'get_current_weather',\n",
    "            'description' : 'Get the current weather in a given location',\n",
    "            'parameters' : {\n",
    "                'type' : 'object',\n",
    "            'properties' : {\n",
    "            'location' : {\n",
    "                'type' : 'string',\n",
    "                'description' : 'The city or state e.g san francisco, CA',\n",
    "            },\n",
    "                'unit' : {'type' : 'string', 'enum' : ['celsius' , 'farenheit']},\n",
    "            },\n",
    "                'required' : ['location'],\n",
    "            },    \n",
    "\n",
    "         },\n",
    "    }\n",
    "\n",
    "    ],\n",
    "\n",
    "    response : ChatCompletion = client.chat.completions.create(\n",
    "\n",
    "        model = 'gpt-3.5-model-1106',\n",
    "        messages = messages,\n",
    "        tools = tools,\n",
    "        tool_choice = 'auto',\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
